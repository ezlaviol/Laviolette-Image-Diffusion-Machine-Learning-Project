{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Latent Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dg0l8uzpFLUp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import copy\n",
    "import math\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from Unet import Unet\n",
    "\n",
    "from diffusers.models import AutoencoderKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "lr = 2e-5\n",
    "\n",
    "train_epoch = 3000\n",
    "\n",
    "# data_loader\n",
    "latent_size = 32\n",
    "\n",
    "data_set_root = \"../../datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Use a GPU if avaliable </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwzLOOlx6KxE"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpu_indx  = 1\n",
    "device = torch.device(gpu_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDataset(Dataset):\n",
    "    def __init__(self, latent_dir):\n",
    "        self.latent_dir = latent_dir\n",
    "        self.latent_files = sorted(os.listdir(latent_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.latent_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        latent_file = self.latent_files[idx]\n",
    "        latent = np.load(os.path.join(self.latent_dir, latent_file))\n",
    "        return torch.tensor(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_root = \".\"\n",
    "trainset = LatentDataset(data_set_root)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine schedual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_alphas_bar(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, steps, steps)\n",
    "    alphas_bar = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_bar = alphas_bar / alphas_bar[0]\n",
    "    return alphas_bar[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Cold Diffusion Process \n",
    "We're implementing DDIM, specifically cold diffusion, which can use any transformation, however we are just doing de-noising.\n",
    "\n",
    "[Cold Diffusion](https://arxiv.org/pdf/2208.09392.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_from_x0(curr_img, img_pred, alpha):\n",
    "    return (curr_img - alpha.sqrt() * img_pred)/((1 - alpha).sqrt() + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_diffuse(diffusion_model, sample_in, total_steps):\n",
    "    diffusion_model.eval()\n",
    "    bs = sample_in.shape[0]\n",
    "    alphas = torch.flip(cosine_alphas_bar(total_steps), (0,)).to(device)\n",
    "    random_sample = copy.deepcopy(sample_in)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(total_steps - 1):\n",
    "            index = (i * torch.ones(bs, device=sample_in.device)).long()\n",
    "\n",
    "            img_output = diffusion_model(random_sample, index)\n",
    "\n",
    "            noise = noise_from_x0(random_sample, img_output, alphas[i])\n",
    "            x0 = img_output\n",
    "\n",
    "            rep1 = alphas[i].sqrt() * x0 + (1 - alphas[i]).sqrt() * noise\n",
    "            rep2 = alphas[i + 1].sqrt() * x0 + (1 - alphas[i + 1]).sqrt() * noise\n",
    "\n",
    "            random_sample += rep2 - rep1\n",
    "\n",
    "        index = ((total_steps - 1) * torch.ones(bs, device=sample_in.device)).long()\n",
    "        img_output = diffusion_model(random_sample, index)\n",
    "\n",
    "    return img_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader itterable object\n",
    "dataiter = iter(train_loader)\n",
    "# Sample from the itterable object\n",
    "latents = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9820,
     "status": "ok",
     "timestamp": 1570750148112,
     "user": {
      "displayName": "Yunyan Xing",
      "photoUrl": "",
      "userId": "15587527606127278468"
     },
     "user_tz": -660
    },
    "id": "FL0LtpmwFLVA",
    "outputId": "9f67f2bd-db73-4b7d-be3e-365776d09ede"
   },
   "outputs": [],
   "source": [
    "timesteps = 500\n",
    "\n",
    "# network\n",
    "u_net = Unet(channels=latents.shape[1],\n",
    "             img_size=latent_size,\n",
    "             out_dim=latents.shape[1],\n",
    "             dim=64,\n",
    "             dim_mults=(1, 2, 4, 8)).to(device)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(u_net.parameters(), lr=lr)\n",
    "\n",
    "# Scaler for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "alphas = torch.flip(cosine_alphas_bar(timesteps), (0,)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in u_net.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gbwhfk6AFLVD"
   },
   "outputs": [],
   "source": [
    "loss_log = []\n",
    "mean_loss = 0\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Checkpoint\n",
    "# cp = torch.load(\"latent_u_net.pt\")\n",
    "# u_net.load_state_dict(cp[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(cp[\"optimizer_state_dict\"])\n",
    "# loss_log = cp[\"train_data_logger\"]\n",
    "# start_epoch = cp[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "error",
     "timestamp": 1570754566661,
     "user": {
      "displayName": "Yunyan Xing",
      "photoUrl": "",
      "userId": "15587527606127278468"
     },
     "user_tz": -660
    },
    "id": "IVBfpjOkFLVH",
    "outputId": "adfcd384-2571-4071-8c30-ad2f66a5f2f1"
   },
   "outputs": [],
   "source": [
    "pbar = trange(start_epoch, train_epoch, leave=False, desc=\"Epoch\")    \n",
    "u_net.train()\n",
    "for epoch in pbar:\n",
    "    pbar.set_postfix_str('Loss: %.4f' % (mean_loss/len(train_loader)))\n",
    "    mean_loss = 0\n",
    "\n",
    "    for i, (latents) in enumerate(tqdm(train_loader, leave=False)):        \n",
    "        latents = latents.to(device)\n",
    "        \n",
    "        #the size of the current minibatch\n",
    "        bs = latents.shape[0]\n",
    "\n",
    "        rand_index = torch.randint(timesteps, (bs, ), device=device)\n",
    "        random_sample = torch.randn_like(latents)\n",
    "        alpha_batch = alphas[rand_index].reshape(bs, 1, 1, 1)\n",
    "        \n",
    "        noise_input = alpha_batch.sqrt() * latents + (1 - alpha_batch).sqrt() * random_sample\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            latent_pred = u_net(noise_input, rand_index)\n",
    "            loss = F.l1_loss(latent_pred, latents)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        #log the generator training loss\n",
    "        loss_log.append(loss.item())\n",
    "        mean_loss += loss.item()\n",
    "\n",
    "    torch.save({'epoch': epoch + 1,\n",
    "                'train_data_logger': loss_log,\n",
    "                'model_state_dict': u_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                 }, \"latent_u_net.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1570754571230,
     "user": {
      "displayName": "Yunyan Xing",
      "photoUrl": "",
      "userId": "15587527606127278468"
     },
     "user_tz": -660
    },
    "id": "a753TY7Z6KxV",
    "outputId": "6b7ebf6d-1354-4776-fe13-9b6f7e18eeae"
   },
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.plot(loss_log[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1570754573085,
     "user": {
      "displayName": "Yunyan Xing",
      "photoUrl": "",
      "userId": "15587527606127278468"
     },
     "user_tz": -660
    },
    "id": "VdN0meY8FLVK",
    "outputId": "1c97838e-e848-4016-863d-b14d9ddc2b8d"
   },
   "outputs": [],
   "source": [
    "latent_noise = 0.5 * torch.randn(8, 4, latent_size, latent_size, device=device)\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        fake_latents = cold_diffuse(u_net, latent_noise, total_steps=timesteps)\n",
    "        fake_sample = vae.decode(fake_latents / 0.18215).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "out = vutils.make_grid(fake_sample.detach().float().cpu(), nrow=4, normalize=True)\n",
    "_ = plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DCGAN_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
